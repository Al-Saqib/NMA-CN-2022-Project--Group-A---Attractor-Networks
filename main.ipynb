{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "OXnmTnJP3NSB",
      "metadata": {
        "id": "OXnmTnJP3NSB"
      },
      "source": [
        "# Hopfield Network Attractor Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebed637e-6801-43e7-ace9-0ec034e17c2e",
      "metadata": {
        "id": "ebed637e-6801-43e7-ace9-0ec034e17c2e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import hopfield\n",
        "import learning_rules as lrn\n",
        "import activation_functions as afn\n",
        "import utilities as uti\n",
        "from datasets import Dataset_demoletters, Dataset_MNIST, Dataset_Demyan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "203ee584-1de6-4b8f-bc13-ef4e15834143",
      "metadata": {
        "id": "203ee584-1de6-4b8f-bc13-ef4e15834143"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a376f438-6832-4e22-9a74-a31cfa76d21f",
      "metadata": {
        "id": "a376f438-6832-4e22-9a74-a31cfa76d21f"
      },
      "source": [
        "### Dataset 2 (Demo, whole letters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55bc7e1c-989b-46af-aa37-90ac8b2be088",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55bc7e1c-989b-46af-aa37-90ac8b2be088",
        "outputId": "38e4fb5f-3a1c-4bd5-b6a0-6cc1f13c39d9"
      },
      "outputs": [],
      "source": [
        "ds_demo = Dataset_demoletters()\n",
        "X_demo = ds_demo.get_data(res = 60)\n",
        "X_demo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09effa60",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_demo.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cRWUtYa3A2I5",
      "metadata": {
        "id": "cRWUtYa3A2I5"
      },
      "source": [
        "### Dataset 3 (MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sTYYJtyJA5ww",
      "metadata": {
        "id": "sTYYJtyJA5ww"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset_MNIST\n",
        "dataset_mnist = Dataset_MNIST()\n",
        "\n",
        "X_mnist = dataset_mnist.get_data()\n",
        "print(X_mnist.shape)\n",
        "dataset_mnist.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DZGxbf2B3WPT",
      "metadata": {
        "id": "DZGxbf2B3WPT"
      },
      "source": [
        "### Dataset 4(Demyan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G6eRiQcl4bK_",
      "metadata": {
        "id": "G6eRiQcl4bK_"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset_Demyan\n",
        "dd = Dataset_Demyan()\n",
        "dd.get_data()\n",
        "dd.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbf0c67a-7496-4de1-9f88-8823f168b749",
      "metadata": {
        "id": "fbf0c67a-7496-4de1-9f88-8823f168b749"
      },
      "source": [
        "# Training and validation process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f74d9f32-d8c3-4e8a-88a1-58fae0a32eba",
      "metadata": {
        "id": "f74d9f32-d8c3-4e8a-88a1-58fae0a32eba"
      },
      "source": [
        "### Demo for dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "likCT4U3nxIF",
      "metadata": {
        "id": "likCT4U3nxIF"
      },
      "outputs": [],
      "source": [
        "# Setup and train\n",
        "np.random.seed(0)\n",
        "letter_index = [0,1 ,2,3]\n",
        "letter_res = 4\n",
        "\n",
        "all_letter_dataset = ds_demo.LETTERS_RESOLUTION[letter_res][letter_index]\n",
        "\n",
        "# all_letter_dataset = np.random.randint(0, 1)\n",
        "n_image, image_size = all_letter_dataset.shape\n",
        "print(f\"Num of images = {n_image}\")\n",
        "\n",
        "hop_net = hopfield.HopfieldNetwork()\n",
        "hop_net.training_step(all_letter_dataset, \"hebbian\")\n",
        "\n",
        "# alphabet preview\n",
        "letter_preview = ds_demo.LETTERS_RESOLUTION[letter_res]\n",
        "print(letter_preview.shape)\n",
        "for i in range(9):\n",
        "    for j in range(9):\n",
        "        arr = letter_preview[9 * i + j]\n",
        "        ax = plt.subplot(9, 9, i * 9 + j + 1)\n",
        "        uti.show_letter(arr, ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pYZkGT2_zZ6S",
      "metadata": {
        "id": "pYZkGT2_zZ6S"
      },
      "outputs": [],
      "source": [
        "for (i, j) in [(0, 1), (0, 2), (0, 3)]:\n",
        "  print(i, j, np.corrcoef(all_letter_dataset[i], all_letter_dataset[j])[0][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a9e0641-ab67-4c80-a271-7745f249c299",
      "metadata": {
        "id": "7a9e0641-ab67-4c80-a271-7745f249c299"
      },
      "outputs": [],
      "source": [
        "# TODO: try to implement this thing where it shows the letters we're using?\n",
        "# I duno how to do it in one plot...\n",
        "\n",
        "# Show chosen letters\n",
        "# for i, ltr in enumerate(all_letter_dataset):\n",
        "#     ax = plt.subplot(2, graph_len, i+1)\n",
        "#     show_letter(ltr, ax)\n",
        "\n",
        "# Run the inference\n",
        "\n",
        "noise_level = .0\n",
        "# n_test_samples = 1000\n",
        "n_test_samples = 10\n",
        "n_iter = 100\n",
        "show_last_n_letters = 3\n",
        "for i in range(n_test_samples):\n",
        "    # pick random image\n",
        "    letter_idx = np.random.randint(0, n_image)\n",
        "\n",
        "    # set custom letter index\n",
        "    # letter_idx = 1\n",
        "\n",
        "    # add noise\n",
        "    x_test = all_letter_dataset[letter_idx].copy()\n",
        "    x_test = uti.add_noise(x_test, noise_level=noise_level)\n",
        "    Xs = hop_net.inference_step(x_test, n_iter)\n",
        "\n",
        "    # plot input\n",
        "    ax = plt.subplot(n_test_samples, 2, i*2+1)\n",
        "    uti.show_letter(x_test, ax)\n",
        "    ax = plt.subplot(n_test_samples, 2, i*2+2)\n",
        "    uti.show_letter(Xs[-1], ax)\n",
        "\n",
        "    # # plot last n entries\n",
        "    # for i, X in enumerate(Xs[-3:]):\n",
        "    #     ax = plt.subplot(1, show_last_n_letters + 2, i+3)\n",
        "    #     show_letter(X, ax)\n",
        "        \n",
        "    # TODO: evaluate the function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WFtuBRFXFJiS",
      "metadata": {
        "id": "WFtuBRFXFJiS"
      },
      "source": [
        "### A demo for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T49XaJ3NFIMC",
      "metadata": {
        "id": "T49XaJ3NFIMC"
      },
      "outputs": [],
      "source": [
        "# np.random.seed(0)\n",
        "\n",
        "# all_letter_dataset = uti.generate_all_letter_dataset(img, new_size = 150)\n",
        "# all_letter_dataset = all_letter_dataset[[10, 20, 30, 5]]\n",
        "# # all_letter_dataset = all_letter_dataset[::-1]\n",
        "# n_image, image_size = all_letter_dataset.shape\n",
        "# print(f\"Num of images = {n_image}\")\n",
        "\n",
        "# hop_net = HopfieldNetwork()\n",
        "# hop_net.training_step(all_letter_dataset, \"hebbian\")\n",
        "\n",
        "# noise_level = .20\n",
        "# # n_test_samples = 1000\n",
        "# n_test_samples = 1\n",
        "# n_iter = 1000\n",
        "# for i in range(n_test_samples):\n",
        "#     # add noise\n",
        "#     # random_idx = np.random.randint(0, n_image - 1)\n",
        "#     random_idx = 3\n",
        "#     print(random_idx)\n",
        "#     x_test = all_letter_dataset[random_idx].copy()\n",
        "#     x_test = add_noise(x_test, noise_level=noise_level)\n",
        "#     is_correct, error = hop_net.score(x_test, random_idx)\n",
        "#     print(is_correct, error)\n",
        "#     if i == 0:\n",
        "#       fig, axs = plt.subplots(1, 6)\n",
        "#       show_letter(all_letter_dataset[0], axs[0])\n",
        "#       show_letter(all_letter_dataset[1], axs[1])\n",
        "#       show_letter(all_letter_dataset[2], axs[2])\n",
        "#       show_letter(all_letter_dataset[3], axs[3])\n",
        "#       show_letter(x_test, axs[4])\n",
        "#       show_letter(hop_net.inference_step(x_test)[-1], axs[5])\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YiRr1safhDYV",
      "metadata": {
        "id": "YiRr1safhDYV"
      },
      "source": [
        "### Demo for dataset 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DZBiqLtTlaGU",
      "metadata": {
        "id": "DZBiqLtTlaGU"
      },
      "outputs": [],
      "source": [
        "X_mnist[0].min(),X_mnist[0].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6K6q4oRHlqPV",
      "metadata": {
        "id": "6K6q4oRHlqPV"
      },
      "outputs": [],
      "source": [
        "n_images = 10\n",
        "all_letter_dataset = X_mnist[:n_images].copy()\n",
        "all_letter_dataset[all_letter_dataset < 10] = -1\n",
        "all_letter_dataset[all_letter_dataset >= 10] = 1\n",
        "\n",
        "for i in range(n_images):\n",
        "  ax = plt.subplot(1, n_images, i+1)\n",
        "  uti.show_letter(all_letter_dataset[i], ax)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZE4tlLE9hFP_",
      "metadata": {
        "id": "ZE4tlLE9hFP_"
      },
      "outputs": [],
      "source": [
        "hop_net = hopfield.HopfieldNetwork()\n",
        "hop_net.training_step(all_letter_dataset, \"hebbian\")\n",
        "\n",
        "noise_level = .20\n",
        "# n_test_samples = 1000\n",
        "n_test_samples = 50\n",
        "n_iter = 1000\n",
        "for i in range(n_test_samples):\n",
        "    # add noise\n",
        "    random_idx = np.random.randint(0, n_images)\n",
        "    # random_idx = 3\n",
        "    x_test = all_letter_dataset[random_idx].copy()\n",
        "    x_test = uti.add_noise(x_test, noise_level=noise_level)\n",
        "    Xs = hop_net.inference_step(x_test, 10)\n",
        "    is_correct, error = hop_net._validate(x_test, random_idx)\n",
        "    print(random_idx, is_correct, error)\n",
        "\n",
        "    ax = plt.subplot(n_test_samples, 2, i * 2 +1)\n",
        "    uti.show_letter(x_test, ax)\n",
        "    ax = plt.subplot(n_test_samples, 2, i * 2 +2)\n",
        "    uti.show_letter(Xs[-1], ax)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hpSYFn-q73pz",
      "metadata": {
        "id": "hpSYFn-q73pz"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(hop_net.weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WLO1cCk464xW",
      "metadata": {
        "id": "WLO1cCk464xW"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(hop_net.weights[:100, :100])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aV_lValM7Tsp",
      "metadata": {
        "id": "aV_lValM7Tsp"
      },
      "source": [
        "### Demo for Dataset 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "foXJxhl-7WWW",
      "metadata": {
        "id": "foXJxhl-7WWW"
      },
      "outputs": [],
      "source": [
        "# all_images_dem\n",
        "all_images_dem = dd.get_data()\n",
        "\n",
        "hop_net = hopfield.HopfieldNetwork()\n",
        "hop_net.TS_storkey(all_images_dem)\n",
        "\n",
        "noise_level = .0\n",
        "# n_test_samples = 1000\n",
        "n_test_samples = 1\n",
        "n_iter = 1000\n",
        "n_images = len(all_images_dem)\n",
        "for i in range(n_test_samples):\n",
        "    # add noise\n",
        "    # random_idx = np.random.randint(0, n_images)\n",
        "    random_idx = 2\n",
        "    x_test = all_images_dem[random_idx].copy()\n",
        "    x_test = uti.add_noise(x_test, noise_level=noise_level)\n",
        "    Xs = hop_net.inference_step(x_test, 10)\n",
        "    is_correct, error = hop_net._validate(x_test, random_idx)\n",
        "    print(random_idx, is_correct, error)\n",
        "\n",
        "    ax = plt.subplot(n_test_samples, 2, i * 2 + 1)\n",
        "    uti.show_letter(x_test, ax)\n",
        "    ax = plt.subplot(n_test_samples, 2, i * 2 + 2)\n",
        "    uti.show_letter(Xs[-1], ax)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sLqtgJGhdzKg",
      "metadata": {
        "id": "sLqtgJGhdzKg"
      },
      "source": [
        "# Let's do experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zkSb71ird2F2",
      "metadata": {
        "id": "zkSb71ird2F2"
      },
      "source": [
        "### Exp 1: only changing number of neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l3NukCefd6C9",
      "metadata": {
        "id": "l3NukCefd6C9"
      },
      "outputs": [],
      "source": [
        "res = 16\n",
        "ninput = 4\n",
        "noise_level = .20\n",
        "# n_test_samples = 1000\n",
        "n_test_samples = 10\n",
        "n_iter = 4\n",
        "show_last_n_letters = 3\n",
        "np.random.seed(4)\n",
        "\n",
        "def do_test(res, dataset, noise_level, n_test_samples, show_last_n_letters):\n",
        "  ninput = dataset.shape[0]\n",
        "  hop_net = hopfield.HopfieldNetwork()\n",
        "  hop_net.training_step(dataset, \"hebbian\")\n",
        "  # for i in range(ninput):\n",
        "  #   ax = plt.subplot(1, ninput, i+1)\n",
        "  #   show_letter(dataset[i], ax)\n",
        "  pm = hopfield.PerformanceMetric()\n",
        "\n",
        "  for i in range(n_test_samples):\n",
        "    # pick random image\n",
        "    letter_idx = np.random.randint(0, ninput - 1)\n",
        "    # set custom letter index\n",
        "    # letter_idx = 1\n",
        "\n",
        "    # add noise\n",
        "    x_test_raw = all_letter_dataset[letter_idx].copy()\n",
        "    x_test = uti.add_noise(x_test_raw, noise_level=noise_level)\n",
        "    Xs = hop_net.inference_step(x_test, n_iter)\n",
        "    \n",
        "    is_correct, error = hop_net._validate(Xs[-1], letter_idx)\n",
        "    # print(hop_net.time())\n",
        "    # print(hop_net.energy())\n",
        "    # print(is_correct, error)\n",
        "    pm.time.append(hop_net.time())\n",
        "    pm.energy.append(hop_net.energy())\n",
        "    pm.is_correct.append(is_correct)\n",
        "    pm.error.append(error)\n",
        "  return pm\n",
        "    \n",
        "    # print(hop_net.perf())\n",
        "    # # plot input\n",
        "    # ax = plt.subplot(1, show_last_n_letters + 1, 1)\n",
        "    # show_letter(x_test_raw, ax)\n",
        "\n",
        "    # # plot last n entries\n",
        "    # for i, X in enumerate(Xs[-3:]):\n",
        "    #     ax = plt.subplot(1, show_last_n_letters + 1, i+2)\n",
        "    #     show_letter(X, ax)\n",
        "\n",
        "# this_letter_dataset = LETTERS_RESOLUTION[letter_res][range(0, ninput)]\n",
        "all_letter_dataset = X_mnist[:ninput]\n",
        "pm = do_test(res, all_letter_dataset, noise_level, n_test_samples, show_last_n_letters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wtBscoS5pnXl",
      "metadata": {
        "id": "wtBscoS5pnXl"
      },
      "outputs": [],
      "source": [
        "# pms = []\n",
        "# min_res, max_res = 1, 10\n",
        "# n_test_samples = 30\n",
        "# neurons = [x**2 for x in range(min_res, max_res)]\n",
        "# np.random.seed(10)\n",
        "# for res in range(min_res, max_res):\n",
        "#   pm = do_test(res, ninput, noise_level, n_test_samples, show_last_n_letters)\n",
        "#   pms.append(pm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mGePiq5diWuU",
      "metadata": {
        "id": "mGePiq5diWuU"
      },
      "source": [
        "# Plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SKASe5G-f5_w",
      "metadata": {
        "id": "SKASe5G-f5_w"
      },
      "outputs": [],
      "source": [
        "pms = [pm]\n",
        "neurons = [28 * 28]\n",
        "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "# 1\n",
        "ax_num_acc = axs[0][0]\n",
        "ax_num_acc.plot(neurons, [np.mean(pm.is_correct) for pm in pms])\n",
        "ax_num_acc.set_xlabel('#Neurons')\n",
        "ax_num_acc.set_ylabel(\"Accuracy\")\n",
        "ax_num_acc.set_xticks(neurons)\n",
        "ax_num_acc.set_title(f\"#Neuron v.s. Accuracy (#trial = {n_test_samples}, #input_sample={ninput})\")\n",
        "\n",
        "\n",
        "# ax timestep accuracy\n",
        "ax_time_acc = axs[0][1]\n",
        "ax_time_acc.scatter([np.mean(pm.time) for pm in pms], [np.mean(pm.is_correct) for pm in pms])\n",
        "ax_time_acc.set_xlabel(f\"Mean timestamp on {n_test_samples} trials\")\n",
        "ax_time_acc.set_ylabel(\"Accuracy\")\n",
        "ax_time_acc.set_title(\"Mean timestamp v.s. Accuracy\")\n",
        "\n",
        "# ax energy accuracy\n",
        "ax_energy_acc = axs[1][0]\n",
        "ax_energy_acc.scatter([np.mean(pm.energy) for pm in pms], [np.mean(pm.is_correct) for pm in pms])\n",
        "ax_energy_acc.set_xlabel(f\"Mean energy on {n_test_samples} trials\")\n",
        "ax_energy_acc.set_ylabel(\"Accuracy\")\n",
        "ax_energy_acc.set_title(\"Mean energy v.s. Accuracy\")\n",
        "\n",
        "# ax energy accuracy\n",
        "ax_energy_time = axs[1][1]\n",
        "ax_energy_time.scatter([np.mean(pm.energy) for pm in pms], [np.mean(pm.time) for pm in pms])\n",
        "ax_energy_time.set_xlabel(\"Mean energy\")\n",
        "ax_energy_time.set_ylabel(\"Mean Timestamp\")\n",
        "ax_energy_time.set_title(\"Mean energy v.s. Mean Timestamp\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WscgaV2wuyKl",
      "metadata": {
        "id": "WscgaV2wuyKl"
      },
      "source": [
        "### Exp2: Change the learning rule / activation functin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sxMOqQeHu3ey",
      "metadata": {
        "id": "sxMOqQeHu3ey"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f1b6c3c4-d623-475e-9f8b-228f5b835ed5",
      "metadata": {
        "id": "f1b6c3c4-d623-475e-9f8b-228f5b835ed5"
      },
      "source": [
        "# Plotting Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "591cd4bd-5398-40b1-b855-058378c03b2e",
      "metadata": {
        "id": "591cd4bd-5398-40b1-b855-058378c03b2e"
      },
      "outputs": [],
      "source": [
        "# neurons = [25, 36, 49, 64, 81]\n",
        "# accuracy = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "# time = [10, 50, 30, 10, 20]\n",
        "\n",
        "# fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
        "# ax1.plot(neurons, accuracy)\n",
        "# ax1.set_xlabel(\"#Neurons\")\n",
        "# ax1.set_ylabel(\"Accuracy\")\n",
        "# ax1.set_ylim(0, 1)\n",
        "\n",
        "# ax2.plot(neurons, time)\n",
        "# ax2.set_xlabel(\"#Neurons\")\n",
        "# ax2.set_ylabel(\"Time\")\n",
        "\n",
        "# ax3.plot(time, accuracy)\n",
        "# ax3.set_xlabel(\"Time\")\n",
        "# ax3.set_ylabel(\"Accuracy\")\n",
        "# ax3.set_ylim(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tLTk84sA-2G4",
      "metadata": {
        "id": "tLTk84sA-2G4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "a376f438-6832-4e22-9a74-a31cfa76d21f",
        "cRWUtYa3A2I5",
        "f74d9f32-d8c3-4e8a-88a1-58fae0a32eba",
        "WFtuBRFXFJiS",
        "YiRr1safhDYV",
        "sLqtgJGhdzKg",
        "f1b6c3c4-d623-475e-9f8b-228f5b835ed5"
      ],
      "name": "main_bjm_addplot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "1d1026617dd78001c52a204c5cd2cde2efafd1a3b285591fb0f82885a58dba3b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
